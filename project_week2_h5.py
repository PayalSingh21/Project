# -*- coding: utf-8 -*-
"""Project_week2_h5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hF2PEtDACJslR37dw5MNRrx_Ivi43eK8
"""

#Import the libraries 

import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, Reshape, Dropout, Activation
from keras.layers.advanced_activations import LeakyReLU
from keras.layers import Conv3D, MaxPooling3D
from keras.utils import to_categorical
from keras.preprocessing import image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
#from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from keras.utils import to_categorical
from tqdm import tqdm
from sklearn.metrics import accuracy_score, confusion_matrix
from keras.utils import to_categorical
from mpi4py import MPI
import h5py

#Loading data and finding out the array names

#For training data

train = h5py.File(r'/content/ply_data_train0.h5', 'r')
# List all groups
print("Keys: %s" % train.keys())
pclKey_train = list(train.keys())[0]
print("plc: %s" % pclKey_train)
labelKey_train= list(train.keys())[1]
print("label: %s" % labelKey_train)
# Get the data 
dataNP_train=np.asarray(train[pclKey_train])
#print("data: %s" % dataNP_train)
labelNP_train=np.asarray(train[labelKey_train])
#print("label: %s" % labelNP_train)

#For testing data

test = h5py.File(r'/content/ply_data_test0.h5', 'r')
# List all groups
print("Keys: %s" % test.keys())
pclKey_test = list(test.keys())[0]
print("plc: %s" % pclKey_test)
labelKey_test= list(test.keys())[1]
print("label: %s" % labelKey_test)
# Get the data 
dataNP_test=np.asarray(test[pclKey_test])
#print("data: %s" % dataNP_test)
labelNP_test=np.asarray(test[labelKey_test])
#print("label: %s" % labelNP_test)

print(list(train))
print(train['data'].shape)
#print(train['faceId'].shape)
print(train['label'].shape)
#print(train['normal'].shape)

print(list(test))
print(test['data'].shape)
print(test['label'].shape)

data_train = train.get('data').value
data_train.dtype

#X_train, Y_train = shuffle(train['data'], train['label'])
#X_test, Y_test = shuffle(test['data'], test['label'])

X_train = train['data']
Y_train = train['label']
X_test = test['data']
Y_test = test['label']

#Define the model structure.
#We will create a simple architecture with 2 convolutional layers, one dense hidden layer and an output layer

from keras import backend as K
K.clear_session()
model = Sequential()
model.add(Reshape((2048, 2048, 3, 1 ), input_shape=(2048, 2048, 3)))
model.add(Conv3D(input_shape=(2048, 2048, 3, 1), filters=1, kernel_size=(5, 5, 5), strides=(2, 2, 2) , padding='same'))
model.add(Conv3D(32, kernel_size=(5, 5, 5),activation='relu',input_shape=(2048, 2048, 3, 1), padding='same'))
model.add(Conv3D(64, (5, 5, 5), activation='relu', padding='same'))
model.add(Activation(LeakyReLU(alpha=0.1)))
#model.add(MaxPooling3D(pool_size=(2, 2, 2)))
model.add(Dropout(rate=0.3))
model.add(Conv3D(filters=30, kernel_size=(3,3,3) , padding='same'))
model.add(Activation(LeakyReLU(alpha=0.1)))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=None))
model.add(Dropout(rate=0.4))
model.add(Flatten())
model.add(Dense(units=128, activation='relu'))
model.add(Dropout(rate=0.5))
model.add(Dense(units=81920, kernel_initializer='normal', activation='relu'))
model.add(Activation("softmax"))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy"])
#model.load_weights("modelnet10.npz")
print (model.summary())

print(X_train.shape)
print(Y_train.shape)

X_train = to_categorical(X_train)
#Y_train = keras.utils.to_categorical(Y_train, num_classes=10)

print(X_train.shape)

Y_train = to_categorical(Y_train)
#Y_train = keras.utils.to_categorical(Y_train, num_classes=10)

print(Y_train.shape)

#X_train = to_categorical(X_train)
#Y_train = keras.utils.to_categorical(Y_train, num_classes=10)

#print(X_train.shape)

X_train = X_train.reshape(-1, 2048, 2048, 3)
Y_train = Y_train.reshape(1, 81920)

print(X_train.shape)
print(Y_train.shape)

model.compile(loss='categorical_crossentropy',
              optimizer=keras.optimizers.Adam(lr=0.001),
              metrics=['accuracy'])

model.fit(X_train, Y_train, batch_size=256, epochs=10, verbose=2,
          validation_split=0.2, shuffle=True)

from sklearn.metrics import accuracy_score

Y_test_pred = np.argmax(model.predict(X_test), axis=1)
print('Test accuracy: {:.3f}'.format(accuracy_score(Y_test, Y_test_pred)))

conf = confusion_matrix(Y_test, Y_test_pred)
avg_per_class_acc = np.mean(np.diagonal(conf) / np.sum(conf, axis=1))
print('Confusion matrix:\n{}'.format(conf))
print('Average per-class accuracy: {:.3f}'.format(avg_per_class_acc))





